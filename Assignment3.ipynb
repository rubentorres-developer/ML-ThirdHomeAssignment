{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "190fb39a",
   "metadata": {},
   "source": [
    "# Machine Learning 2023/2024\n",
    "\n",
    "## Third Home Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4df32ad",
   "metadata": {},
   "source": [
    "**Group Number:** 10\n",
    "\n",
    "**Group Elements:**\n",
    "- André Santos (fc53323)\n",
    "- Filipe Santos (fc53304)\n",
    "- João Martins (fc62532)\n",
    "- Rúben Torres (fc62531)\n",
    "\n",
    "**Hours Worked:**\n",
    "- André Santos (10h)\n",
    "- Filipe Santos (10h)\n",
    "- João Martins (10h)\n",
    "- Rúben Torres (10h)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c477d4",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccfa3272",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier, plot_tree\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, LogisticRegression\n",
    "#from statsmodels.api import OLS, add_constant\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import explained_variance_score, mean_squared_error, max_error, mean_absolute_error\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, matthews_corrcoef, confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import (PowerTransformer)\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.decomposition import KernelPCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da94a3b",
   "metadata": {},
   "source": [
    "### Loading and understanding the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "598351a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "unpickled_df = pd.read_pickle(\"drd2_data.pickle\")\n",
    "#unpickled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d77ed14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7337, 2132)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(unpickled_df[0]))\n",
    "unpickled_df[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1e8122",
   "metadata": {},
   "source": [
    "Data is splitted upon loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb0cb614",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_ivs, y_train, col_names = pickle.load(open(\"drd2_data.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc145a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for col in (col_names):\n",
    "#    print(\"coluna: \", col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "130a27dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7337, 2132)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "#X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c63e19b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train.tofile('X_train.csv', sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64ef73d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(816, 2132)\n"
     ]
    }
   ],
   "source": [
    "print(X_ivs.shape)\n",
    "#X_ivs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "431538c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7337,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "#y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ec9d0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cols_to_discard = []\n",
    "#for col in range (X_train.shape[1]):\n",
    "#    print(\"coluna: \", col_names[col])\n",
    "#    proportion = (X_train[: col] == 0).mean() * 100\n",
    "#    if proportion > 0:\n",
    "#            print(f\"Proportion of missing values in column { col }: { round(proportion, 2) }%\")\n",
    "#        cols_to_discard.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51bc4e76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2123</th>\n",
       "      <th>2124</th>\n",
       "      <th>2125</th>\n",
       "      <th>2126</th>\n",
       "      <th>2127</th>\n",
       "      <th>2128</th>\n",
       "      <th>2129</th>\n",
       "      <th>2130</th>\n",
       "      <th>2131</th>\n",
       "      <th>2132</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.654947</td>\n",
       "      <td>541.280138</td>\n",
       "      <td>541.656</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.649995</td>\n",
       "      <td>426.197714</td>\n",
       "      <td>426.582</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.154947</td>\n",
       "      <td>348.183778</td>\n",
       "      <td>348.446</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.616176</td>\n",
       "      <td>1455.763803</td>\n",
       "      <td>1456.831</td>\n",
       "      <td>27.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.359725</td>\n",
       "      <td>387.151368</td>\n",
       "      <td>387.886</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7332</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>467.149047</td>\n",
       "      <td>467.513</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7333</th>\n",
       "      <td>0.002193</td>\n",
       "      <td>240.162649</td>\n",
       "      <td>240.350</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7334</th>\n",
       "      <td>0.293481</td>\n",
       "      <td>510.317874</td>\n",
       "      <td>510.802</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7335</th>\n",
       "      <td>0.596804</td>\n",
       "      <td>393.187483</td>\n",
       "      <td>393.556</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7336</th>\n",
       "      <td>0.776976</td>\n",
       "      <td>484.056123</td>\n",
       "      <td>485.462</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7337 rows × 2133 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0            1         2     3     4     5     6     7      8     \\\n",
       "0     0.654947   541.280138   541.656  10.0   1.0   8.0   1.0  10.0   40.0   \n",
       "1     0.649995   426.197714   426.582   5.0   1.0   9.0   1.0   4.0   30.0   \n",
       "2     0.154947   348.183778   348.446   4.0   0.0   3.0   0.0   3.0   26.0   \n",
       "3     0.616176  1455.763803  1456.831  27.0  19.0  23.0  17.0  16.0  105.0   \n",
       "4     0.359725   387.151368   387.886   4.0   0.0   4.0   0.0   4.0   27.0   \n",
       "...        ...          ...       ...   ...   ...   ...   ...   ...    ...   \n",
       "7332  0.000000   467.149047   467.513   6.0   0.0   6.0   0.0   5.0   32.0   \n",
       "7333  0.002193   240.162649   240.350   2.0   0.0   3.0   0.0   2.0   18.0   \n",
       "7334  0.293481   510.317874   510.802   4.0   0.0  10.0   0.0   4.0   37.0   \n",
       "7335  0.596804   393.187483   393.556   4.0   2.0   5.0   1.0   5.0   28.0   \n",
       "7336  0.776976   484.056123   485.462   6.0   1.0   7.0   1.0   6.0   30.0   \n",
       "\n",
       "       9     ...  2123  2124  2125  2126  2127  2128  2129  2130  2131  2132  \n",
       "0      75.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1      60.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2      50.0  ...   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "3     206.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   1.0   1.0  \n",
       "4      50.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "...     ...  ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "7332   56.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "7333   38.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  \n",
       "7334   79.0  ...   0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "7335   55.0  ...   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "7336   52.0  ...   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[7337 rows x 2133 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N,M=X_train.shape\n",
    "N,M\n",
    "v=np.hstack((y_train.reshape((N,1)), X_train))\n",
    "pd.DataFrame(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27cd6c76-8b8d-4e79-b6a7-2808c2faaae9",
   "metadata": {},
   "source": [
    "<h3>Data Treatement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "272f6f3c-e1e3-4b37-aa43-ad4cfd28c311",
   "metadata": {},
   "outputs": [],
   "source": [
    "#powerscaler not ideal for this dataset since it deletes outliers and we believe that the outliers shouldn't be removed from this dataset\n",
    "#scaler = PowerTransformer().fit(X_train)\n",
    "\n",
    "sScaler = StandardScaler()\n",
    "X_train_scaled = sScaler.fit_transform(X_train)\n",
    "X_ivs_scaled = sScaler.transform(X_ivs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc9cff66-ac2c-4074-826c-12ef2947c0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(np.unique(X_train_scaled[: 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90cfa218-0b72-4752-8506-41bb13e457f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_scaled.tofile('X_train_scaled.csv', sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82245a31-69ad-46bd-993d-b827fc1cefea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pode não fazer sentido fazer o scale dos dados cortados. Talvez faça mais sentido fazer o corte sobre os dados já \"scaled\"\n",
    "#X_train_cut_scaled = sScaler.fit_transform(X_train_cut)\n",
    "#X_ivs_cut_scaled = sScaler.transform(X_ivs_cut)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf635db9-0490-45b9-9fe7-0c60bf8c3e47",
   "metadata": {},
   "source": [
    "<h3>selecting features by droping the features with correlation score bellow 0.05 to the dependant variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eaa85ca2-8d13-4e1f-a9e7-aaa4b10d9923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2123</th>\n",
       "      <th>2124</th>\n",
       "      <th>2125</th>\n",
       "      <th>2126</th>\n",
       "      <th>2127</th>\n",
       "      <th>2128</th>\n",
       "      <th>2129</th>\n",
       "      <th>2130</th>\n",
       "      <th>2131</th>\n",
       "      <th>2132</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.654947</td>\n",
       "      <td>0.609921</td>\n",
       "      <td>0.608648</td>\n",
       "      <td>1.098414</td>\n",
       "      <td>-0.081854</td>\n",
       "      <td>0.246156</td>\n",
       "      <td>-0.058057</td>\n",
       "      <td>1.908209</td>\n",
       "      <td>0.737657</td>\n",
       "      <td>0.614996</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.810066</td>\n",
       "      <td>-0.195463</td>\n",
       "      <td>-0.179087</td>\n",
       "      <td>-0.311512</td>\n",
       "      <td>-0.168687</td>\n",
       "      <td>-0.105656</td>\n",
       "      <td>-0.136394</td>\n",
       "      <td>-0.198821</td>\n",
       "      <td>-0.323477</td>\n",
       "      <td>-0.195463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.649995</td>\n",
       "      <td>-0.023790</td>\n",
       "      <td>-0.024513</td>\n",
       "      <td>-0.103427</td>\n",
       "      <td>-0.081854</td>\n",
       "      <td>0.413306</td>\n",
       "      <td>-0.058057</td>\n",
       "      <td>-0.243126</td>\n",
       "      <td>-0.038629</td>\n",
       "      <td>0.032423</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.810066</td>\n",
       "      <td>-0.195463</td>\n",
       "      <td>-0.179087</td>\n",
       "      <td>-0.311512</td>\n",
       "      <td>-0.168687</td>\n",
       "      <td>-0.105656</td>\n",
       "      <td>-0.136394</td>\n",
       "      <td>-0.198821</td>\n",
       "      <td>-0.323477</td>\n",
       "      <td>-0.195463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.154947</td>\n",
       "      <td>-0.453381</td>\n",
       "      <td>-0.454433</td>\n",
       "      <td>-0.343795</td>\n",
       "      <td>-0.477479</td>\n",
       "      <td>-0.589590</td>\n",
       "      <td>-0.508809</td>\n",
       "      <td>-0.601682</td>\n",
       "      <td>-0.349144</td>\n",
       "      <td>-0.355960</td>\n",
       "      <td>...</td>\n",
       "      <td>1.234467</td>\n",
       "      <td>-0.195463</td>\n",
       "      <td>-0.179087</td>\n",
       "      <td>-0.311512</td>\n",
       "      <td>-0.168687</td>\n",
       "      <td>-0.105656</td>\n",
       "      <td>-0.136394</td>\n",
       "      <td>-0.198821</td>\n",
       "      <td>-0.323477</td>\n",
       "      <td>-0.195463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.616176</td>\n",
       "      <td>5.645607</td>\n",
       "      <td>5.644129</td>\n",
       "      <td>5.184672</td>\n",
       "      <td>7.039406</td>\n",
       "      <td>2.753396</td>\n",
       "      <td>7.153978</td>\n",
       "      <td>4.059544</td>\n",
       "      <td>5.783518</td>\n",
       "      <td>5.702803</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.810066</td>\n",
       "      <td>-0.195463</td>\n",
       "      <td>-0.179087</td>\n",
       "      <td>-0.311512</td>\n",
       "      <td>-0.168687</td>\n",
       "      <td>-0.105656</td>\n",
       "      <td>-0.136394</td>\n",
       "      <td>5.029661</td>\n",
       "      <td>3.091413</td>\n",
       "      <td>5.116060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.359725</td>\n",
       "      <td>-0.238802</td>\n",
       "      <td>-0.237426</td>\n",
       "      <td>-0.343795</td>\n",
       "      <td>-0.477479</td>\n",
       "      <td>-0.422441</td>\n",
       "      <td>-0.508809</td>\n",
       "      <td>-0.243126</td>\n",
       "      <td>-0.271515</td>\n",
       "      <td>-0.355960</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.810066</td>\n",
       "      <td>-0.195463</td>\n",
       "      <td>-0.179087</td>\n",
       "      <td>-0.311512</td>\n",
       "      <td>-0.168687</td>\n",
       "      <td>-0.105656</td>\n",
       "      <td>-0.136394</td>\n",
       "      <td>-0.198821</td>\n",
       "      <td>-0.323477</td>\n",
       "      <td>-0.195463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7332</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.201712</td>\n",
       "      <td>0.200698</td>\n",
       "      <td>0.136941</td>\n",
       "      <td>-0.477479</td>\n",
       "      <td>-0.088142</td>\n",
       "      <td>-0.508809</td>\n",
       "      <td>0.115430</td>\n",
       "      <td>0.116628</td>\n",
       "      <td>-0.122930</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.810066</td>\n",
       "      <td>-0.195463</td>\n",
       "      <td>-0.179087</td>\n",
       "      <td>-0.311512</td>\n",
       "      <td>-0.168687</td>\n",
       "      <td>-0.105656</td>\n",
       "      <td>-0.136394</td>\n",
       "      <td>-0.198821</td>\n",
       "      <td>-0.323477</td>\n",
       "      <td>-0.195463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7333</th>\n",
       "      <td>0.002193</td>\n",
       "      <td>-1.048209</td>\n",
       "      <td>-1.049199</td>\n",
       "      <td>-0.824531</td>\n",
       "      <td>-0.477479</td>\n",
       "      <td>-0.589590</td>\n",
       "      <td>-0.508809</td>\n",
       "      <td>-0.960238</td>\n",
       "      <td>-0.970173</td>\n",
       "      <td>-0.822018</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.810066</td>\n",
       "      <td>-0.195463</td>\n",
       "      <td>-0.179087</td>\n",
       "      <td>-0.311512</td>\n",
       "      <td>-0.168687</td>\n",
       "      <td>-0.105656</td>\n",
       "      <td>-0.136394</td>\n",
       "      <td>-0.198821</td>\n",
       "      <td>3.091413</td>\n",
       "      <td>-0.195463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7334</th>\n",
       "      <td>0.293481</td>\n",
       "      <td>0.439425</td>\n",
       "      <td>0.438883</td>\n",
       "      <td>-0.343795</td>\n",
       "      <td>-0.477479</td>\n",
       "      <td>0.580455</td>\n",
       "      <td>-0.508809</td>\n",
       "      <td>-0.243126</td>\n",
       "      <td>0.504771</td>\n",
       "      <td>0.770349</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.810066</td>\n",
       "      <td>-0.195463</td>\n",
       "      <td>-0.179087</td>\n",
       "      <td>3.210153</td>\n",
       "      <td>-0.168687</td>\n",
       "      <td>-0.105656</td>\n",
       "      <td>-0.136394</td>\n",
       "      <td>-0.198821</td>\n",
       "      <td>-0.323477</td>\n",
       "      <td>-0.195463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7335</th>\n",
       "      <td>0.596804</td>\n",
       "      <td>-0.205564</td>\n",
       "      <td>-0.206229</td>\n",
       "      <td>-0.343795</td>\n",
       "      <td>0.313772</td>\n",
       "      <td>-0.255292</td>\n",
       "      <td>-0.058057</td>\n",
       "      <td>0.115430</td>\n",
       "      <td>-0.193886</td>\n",
       "      <td>-0.161769</td>\n",
       "      <td>...</td>\n",
       "      <td>1.234467</td>\n",
       "      <td>-0.195463</td>\n",
       "      <td>-0.179087</td>\n",
       "      <td>-0.311512</td>\n",
       "      <td>-0.168687</td>\n",
       "      <td>-0.105656</td>\n",
       "      <td>-0.136394</td>\n",
       "      <td>-0.198821</td>\n",
       "      <td>-0.323477</td>\n",
       "      <td>-0.195463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7336</th>\n",
       "      <td>0.776976</td>\n",
       "      <td>0.294812</td>\n",
       "      <td>0.299457</td>\n",
       "      <td>0.136941</td>\n",
       "      <td>-0.081854</td>\n",
       "      <td>0.079007</td>\n",
       "      <td>-0.058057</td>\n",
       "      <td>0.473986</td>\n",
       "      <td>-0.038629</td>\n",
       "      <td>-0.278283</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.810066</td>\n",
       "      <td>5.116060</td>\n",
       "      <td>-0.179087</td>\n",
       "      <td>-0.311512</td>\n",
       "      <td>-0.168687</td>\n",
       "      <td>-0.105656</td>\n",
       "      <td>-0.136394</td>\n",
       "      <td>-0.198821</td>\n",
       "      <td>-0.323477</td>\n",
       "      <td>-0.195463</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7337 rows × 2133 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6     \\\n",
       "0     0.654947  0.609921  0.608648  1.098414 -0.081854  0.246156 -0.058057   \n",
       "1     0.649995 -0.023790 -0.024513 -0.103427 -0.081854  0.413306 -0.058057   \n",
       "2     0.154947 -0.453381 -0.454433 -0.343795 -0.477479 -0.589590 -0.508809   \n",
       "3     0.616176  5.645607  5.644129  5.184672  7.039406  2.753396  7.153978   \n",
       "4     0.359725 -0.238802 -0.237426 -0.343795 -0.477479 -0.422441 -0.508809   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "7332  0.000000  0.201712  0.200698  0.136941 -0.477479 -0.088142 -0.508809   \n",
       "7333  0.002193 -1.048209 -1.049199 -0.824531 -0.477479 -0.589590 -0.508809   \n",
       "7334  0.293481  0.439425  0.438883 -0.343795 -0.477479  0.580455 -0.508809   \n",
       "7335  0.596804 -0.205564 -0.206229 -0.343795  0.313772 -0.255292 -0.058057   \n",
       "7336  0.776976  0.294812  0.299457  0.136941 -0.081854  0.079007 -0.058057   \n",
       "\n",
       "          7         8         9     ...      2123      2124      2125  \\\n",
       "0     1.908209  0.737657  0.614996  ... -0.810066 -0.195463 -0.179087   \n",
       "1    -0.243126 -0.038629  0.032423  ... -0.810066 -0.195463 -0.179087   \n",
       "2    -0.601682 -0.349144 -0.355960  ...  1.234467 -0.195463 -0.179087   \n",
       "3     4.059544  5.783518  5.702803  ... -0.810066 -0.195463 -0.179087   \n",
       "4    -0.243126 -0.271515 -0.355960  ... -0.810066 -0.195463 -0.179087   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "7332  0.115430  0.116628 -0.122930  ... -0.810066 -0.195463 -0.179087   \n",
       "7333 -0.960238 -0.970173 -0.822018  ... -0.810066 -0.195463 -0.179087   \n",
       "7334 -0.243126  0.504771  0.770349  ... -0.810066 -0.195463 -0.179087   \n",
       "7335  0.115430 -0.193886 -0.161769  ...  1.234467 -0.195463 -0.179087   \n",
       "7336  0.473986 -0.038629 -0.278283  ... -0.810066  5.116060 -0.179087   \n",
       "\n",
       "          2126      2127      2128      2129      2130      2131      2132  \n",
       "0    -0.311512 -0.168687 -0.105656 -0.136394 -0.198821 -0.323477 -0.195463  \n",
       "1    -0.311512 -0.168687 -0.105656 -0.136394 -0.198821 -0.323477 -0.195463  \n",
       "2    -0.311512 -0.168687 -0.105656 -0.136394 -0.198821 -0.323477 -0.195463  \n",
       "3    -0.311512 -0.168687 -0.105656 -0.136394  5.029661  3.091413  5.116060  \n",
       "4    -0.311512 -0.168687 -0.105656 -0.136394 -0.198821 -0.323477 -0.195463  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "7332 -0.311512 -0.168687 -0.105656 -0.136394 -0.198821 -0.323477 -0.195463  \n",
       "7333 -0.311512 -0.168687 -0.105656 -0.136394 -0.198821  3.091413 -0.195463  \n",
       "7334  3.210153 -0.168687 -0.105656 -0.136394 -0.198821 -0.323477 -0.195463  \n",
       "7335 -0.311512 -0.168687 -0.105656 -0.136394 -0.198821 -0.323477 -0.195463  \n",
       "7336 -0.311512 -0.168687 -0.105656 -0.136394 -0.198821 -0.323477 -0.195463  \n",
       "\n",
       "[7337 rows x 2133 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#new correlation matrix with scaled data\n",
    "v_scaled=np.hstack((y_train.reshape((N,1)), X_train_scaled))\n",
    "pd.DataFrame(v_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4854909b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2123</th>\n",
       "      <th>2124</th>\n",
       "      <th>2125</th>\n",
       "      <th>2126</th>\n",
       "      <th>2127</th>\n",
       "      <th>2128</th>\n",
       "      <th>2129</th>\n",
       "      <th>2130</th>\n",
       "      <th>2131</th>\n",
       "      <th>2132</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.160182</td>\n",
       "      <td>0.160216</td>\n",
       "      <td>0.130117</td>\n",
       "      <td>0.084939</td>\n",
       "      <td>0.151968</td>\n",
       "      <td>0.095929</td>\n",
       "      <td>0.126690</td>\n",
       "      <td>0.157545</td>\n",
       "      <td>0.165189</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011360</td>\n",
       "      <td>0.095138</td>\n",
       "      <td>0.078900</td>\n",
       "      <td>-0.021728</td>\n",
       "      <td>-0.012977</td>\n",
       "      <td>0.001865</td>\n",
       "      <td>0.012468</td>\n",
       "      <td>0.031884</td>\n",
       "      <td>-0.027774</td>\n",
       "      <td>0.058370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.160182</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.919389</td>\n",
       "      <td>0.772557</td>\n",
       "      <td>0.888252</td>\n",
       "      <td>0.784495</td>\n",
       "      <td>0.856242</td>\n",
       "      <td>0.992766</td>\n",
       "      <td>0.973177</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213406</td>\n",
       "      <td>0.019559</td>\n",
       "      <td>0.127229</td>\n",
       "      <td>0.117371</td>\n",
       "      <td>-0.017119</td>\n",
       "      <td>0.053576</td>\n",
       "      <td>0.212881</td>\n",
       "      <td>0.342831</td>\n",
       "      <td>0.173077</td>\n",
       "      <td>0.219727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.160216</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.919128</td>\n",
       "      <td>0.772379</td>\n",
       "      <td>0.888072</td>\n",
       "      <td>0.784320</td>\n",
       "      <td>0.855980</td>\n",
       "      <td>0.992623</td>\n",
       "      <td>0.972956</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213435</td>\n",
       "      <td>0.019583</td>\n",
       "      <td>0.127309</td>\n",
       "      <td>0.117351</td>\n",
       "      <td>-0.017201</td>\n",
       "      <td>0.053498</td>\n",
       "      <td>0.212889</td>\n",
       "      <td>0.342785</td>\n",
       "      <td>0.173016</td>\n",
       "      <td>0.219646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.130117</td>\n",
       "      <td>0.919389</td>\n",
       "      <td>0.919128</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.838103</td>\n",
       "      <td>0.863232</td>\n",
       "      <td>0.843652</td>\n",
       "      <td>0.931528</td>\n",
       "      <td>0.922469</td>\n",
       "      <td>0.905146</td>\n",
       "      <td>...</td>\n",
       "      <td>0.196534</td>\n",
       "      <td>-0.008557</td>\n",
       "      <td>0.095891</td>\n",
       "      <td>0.064926</td>\n",
       "      <td>-0.026235</td>\n",
       "      <td>0.043314</td>\n",
       "      <td>0.181134</td>\n",
       "      <td>0.332638</td>\n",
       "      <td>0.137266</td>\n",
       "      <td>0.205303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.084939</td>\n",
       "      <td>0.772557</td>\n",
       "      <td>0.772379</td>\n",
       "      <td>0.838103</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.704868</td>\n",
       "      <td>0.993448</td>\n",
       "      <td>0.653117</td>\n",
       "      <td>0.774714</td>\n",
       "      <td>0.769215</td>\n",
       "      <td>...</td>\n",
       "      <td>0.185163</td>\n",
       "      <td>-0.032325</td>\n",
       "      <td>0.083849</td>\n",
       "      <td>0.022735</td>\n",
       "      <td>-0.013150</td>\n",
       "      <td>0.045537</td>\n",
       "      <td>0.110449</td>\n",
       "      <td>0.409722</td>\n",
       "      <td>0.210139</td>\n",
       "      <td>0.231743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2128</th>\n",
       "      <td>0.001865</td>\n",
       "      <td>0.053576</td>\n",
       "      <td>0.053498</td>\n",
       "      <td>0.043314</td>\n",
       "      <td>0.045537</td>\n",
       "      <td>0.036037</td>\n",
       "      <td>0.047958</td>\n",
       "      <td>0.038387</td>\n",
       "      <td>0.059813</td>\n",
       "      <td>0.061989</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018420</td>\n",
       "      <td>-0.020652</td>\n",
       "      <td>-0.018922</td>\n",
       "      <td>-0.009945</td>\n",
       "      <td>-0.009870</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.063520</td>\n",
       "      <td>0.047193</td>\n",
       "      <td>0.032638</td>\n",
       "      <td>0.027846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2129</th>\n",
       "      <td>0.012468</td>\n",
       "      <td>0.212881</td>\n",
       "      <td>0.212889</td>\n",
       "      <td>0.181134</td>\n",
       "      <td>0.110449</td>\n",
       "      <td>0.254921</td>\n",
       "      <td>0.115041</td>\n",
       "      <td>0.202605</td>\n",
       "      <td>0.213051</td>\n",
       "      <td>0.218212</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022700</td>\n",
       "      <td>-0.015847</td>\n",
       "      <td>0.075295</td>\n",
       "      <td>-0.020981</td>\n",
       "      <td>-0.004391</td>\n",
       "      <td>0.063520</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.026101</td>\n",
       "      <td>0.049729</td>\n",
       "      <td>0.000372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2130</th>\n",
       "      <td>0.031884</td>\n",
       "      <td>0.342831</td>\n",
       "      <td>0.342785</td>\n",
       "      <td>0.332638</td>\n",
       "      <td>0.409722</td>\n",
       "      <td>0.276091</td>\n",
       "      <td>0.410854</td>\n",
       "      <td>0.233237</td>\n",
       "      <td>0.342548</td>\n",
       "      <td>0.342609</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006494</td>\n",
       "      <td>0.017914</td>\n",
       "      <td>0.009569</td>\n",
       "      <td>-0.004214</td>\n",
       "      <td>-0.020504</td>\n",
       "      <td>0.047193</td>\n",
       "      <td>0.026101</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.123067</td>\n",
       "      <td>0.127682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2131</th>\n",
       "      <td>-0.027774</td>\n",
       "      <td>0.173077</td>\n",
       "      <td>0.173016</td>\n",
       "      <td>0.137266</td>\n",
       "      <td>0.210139</td>\n",
       "      <td>0.177572</td>\n",
       "      <td>0.216401</td>\n",
       "      <td>0.081396</td>\n",
       "      <td>0.184924</td>\n",
       "      <td>0.190152</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004409</td>\n",
       "      <td>-0.026145</td>\n",
       "      <td>0.009127</td>\n",
       "      <td>0.051670</td>\n",
       "      <td>-0.029027</td>\n",
       "      <td>0.032638</td>\n",
       "      <td>0.049729</td>\n",
       "      <td>0.123067</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.082630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2132</th>\n",
       "      <td>0.058370</td>\n",
       "      <td>0.219727</td>\n",
       "      <td>0.219646</td>\n",
       "      <td>0.205303</td>\n",
       "      <td>0.231743</td>\n",
       "      <td>0.119145</td>\n",
       "      <td>0.240242</td>\n",
       "      <td>0.151050</td>\n",
       "      <td>0.226627</td>\n",
       "      <td>0.218560</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004474</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>-0.018317</td>\n",
       "      <td>-0.025196</td>\n",
       "      <td>-0.024145</td>\n",
       "      <td>0.027846</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>0.127682</td>\n",
       "      <td>0.082630</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2133 rows × 2133 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6     \\\n",
       "0     1.000000  0.160182  0.160216  0.130117  0.084939  0.151968  0.095929   \n",
       "1     0.160182  1.000000  0.999998  0.919389  0.772557  0.888252  0.784495   \n",
       "2     0.160216  0.999998  1.000000  0.919128  0.772379  0.888072  0.784320   \n",
       "3     0.130117  0.919389  0.919128  1.000000  0.838103  0.863232  0.843652   \n",
       "4     0.084939  0.772557  0.772379  0.838103  1.000000  0.704868  0.993448   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "2128  0.001865  0.053576  0.053498  0.043314  0.045537  0.036037  0.047958   \n",
       "2129  0.012468  0.212881  0.212889  0.181134  0.110449  0.254921  0.115041   \n",
       "2130  0.031884  0.342831  0.342785  0.332638  0.409722  0.276091  0.410854   \n",
       "2131 -0.027774  0.173077  0.173016  0.137266  0.210139  0.177572  0.216401   \n",
       "2132  0.058370  0.219727  0.219646  0.205303  0.231743  0.119145  0.240242   \n",
       "\n",
       "          7         8         9     ...      2123      2124      2125  \\\n",
       "0     0.126690  0.157545  0.165189  ...  0.011360  0.095138  0.078900   \n",
       "1     0.856242  0.992766  0.973177  ...  0.213406  0.019559  0.127229   \n",
       "2     0.855980  0.992623  0.972956  ...  0.213435  0.019583  0.127309   \n",
       "3     0.931528  0.922469  0.905146  ...  0.196534 -0.008557  0.095891   \n",
       "4     0.653117  0.774714  0.769215  ...  0.185163 -0.032325  0.083849   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "2128  0.038387  0.059813  0.061989  ...  0.018420 -0.020652 -0.018922   \n",
       "2129  0.202605  0.213051  0.218212  ...  0.022700 -0.015847  0.075295   \n",
       "2130  0.233237  0.342548  0.342609  ...  0.006494  0.017914  0.009569   \n",
       "2131  0.081396  0.184924  0.190152  ...  0.004409 -0.026145  0.009127   \n",
       "2132  0.151050  0.226627  0.218560  ...  0.004474  0.000246 -0.018317   \n",
       "\n",
       "          2126      2127      2128      2129      2130      2131      2132  \n",
       "0    -0.021728 -0.012977  0.001865  0.012468  0.031884 -0.027774  0.058370  \n",
       "1     0.117371 -0.017119  0.053576  0.212881  0.342831  0.173077  0.219727  \n",
       "2     0.117351 -0.017201  0.053498  0.212889  0.342785  0.173016  0.219646  \n",
       "3     0.064926 -0.026235  0.043314  0.181134  0.332638  0.137266  0.205303  \n",
       "4     0.022735 -0.013150  0.045537  0.110449  0.409722  0.210139  0.231743  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "2128 -0.009945 -0.009870  1.000000  0.063520  0.047193  0.032638  0.027846  \n",
       "2129 -0.020981 -0.004391  0.063520  1.000000  0.026101  0.049729  0.000372  \n",
       "2130 -0.004214 -0.020504  0.047193  0.026101  1.000000  0.123067  0.127682  \n",
       "2131  0.051670 -0.029027  0.032638  0.049729  0.123067  1.000000  0.082630  \n",
       "2132 -0.025196 -0.024145  0.027846  0.000372  0.127682  0.082630  1.000000  \n",
       "\n",
       "[2133 rows x 2133 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(np.corrcoef(v_scaled.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b92368f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "374"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix = pd.DataFrame(np.corrcoef(v_scaled.T))\n",
    "\n",
    "# Initialize an empty list to store line numbers and values\n",
    "filtered_values_per_line = []\n",
    "\n",
    "# Iterate through the DataFrame and store line numbers and values\n",
    "#for i, row in enumerate(corr_matrix.values):\n",
    "#    line_values = [(j, value) for j, value in enumerate(row) if abs(value) > 0. and abs(value) < 1]\n",
    "#    if line_values:\n",
    "#        filtered_values_per_line.append(line_values)\n",
    "\n",
    "# Display the filtered values for each line\n",
    "#for line_number, values in enumerate(filtered_values_per_line):\n",
    "#    print(f\"Line {line_number}: {values}\")\n",
    "   \n",
    "for row, value in enumerate(corr_matrix.values[0, 1:]):\n",
    "    if value > 0.05:\n",
    "        line_values = (row, value)\n",
    "        filtered_values_per_line.append(line_values)\n",
    "\n",
    "#for values, line_number in enumerate(filtered_values_per_line):\n",
    "    #print(f\"Line {line_number}: {values}\")\n",
    "\n",
    "len(filtered_values_per_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f08cfb4a-f46b-48d0-a0f4-841ab9f71337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1758"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize an empty list to store line numbers and values\n",
    "filtered_values_per_line = []\n",
    "\n",
    "for row, value in enumerate(corr_matrix.values[0, 1:]):\n",
    "    if value < 0.05:\n",
    "        line_values = (row, value)\n",
    "        filtered_values_per_line.append(line_values)\n",
    "\n",
    "features_to_remove = []\n",
    "for values, line_number in enumerate(filtered_values_per_line):\n",
    "    #print(f\"Feature {line_number}: {values}\")\n",
    "    features_to_remove.append(line_number[0])\n",
    "\n",
    "len(filtered_values_per_line)\n",
    "#print (features_to_remove)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8435ada5-e330-4eb6-9c6b-97fb6da18e5f",
   "metadata": {},
   "source": [
    "<h4>New X-train with removed features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a5bda67-9628-4370-a4d8-e34edf6cc899",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7337, 374)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_cut= np.delete(X_train_scaled, features_to_remove, 1)\n",
    "\n",
    "N_cut,M_cut=X_train_cut.shape\n",
    "X_train_cut.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "574ceca3-4ba3-45e9-9ea4-bb69f7108427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(816, 374)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ivs_cut= np.delete(X_ivs_scaled, features_to_remove, 1)\n",
    "\n",
    "X_ivs_cut.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "084e4f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(np.unique(X_train[: 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13f5b72",
   "metadata": {},
   "source": [
    "<h3>Data Treatment redundant (ignore this section, to delete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3cf213e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#powerscaler not ideal for this dataset since it deletes outliers and we believe that the outliers shouldn't be removed from this dataset\n",
    "#scaler = PowerTransformer().fit(X_train)\n",
    "\n",
    "#sScaler = StandardScaler()\n",
    "#X_train_scaled = sScaler.fit_transform(X_train)\n",
    "#X_ivs_scaled = sScaler.transform(X_ivs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cd0b7349",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(np.unique(X_train_scaled[: 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ad84ec36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_scaled.tofile('X_train_scaled.csv', sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4b05a620-75fb-443c-9752-c3bea6e038da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pode não fazer sentido fazer o scale dos dados cortados. Talvez faça mais sentido fazer o corte sobre os dados já \"scaled\"\n",
    "#X_train_cut_scaled = sScaler.fit_transform(X_train_cut)\n",
    "#X_ivs_cut_scaled = sScaler.transform(X_ivs_cut)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e0975c",
   "metadata": {},
   "source": [
    "<h3>Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e949059",
   "metadata": {},
   "source": [
    "<h4>Stepwise fowards feature selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "745da56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To Discard. This approach of feature selection takes to long on big datasets (7000+, 300+)\n",
    "\n",
    "#N,M=X_train_cut.shape\n",
    "\n",
    "#using linear regression for sequential feature selection\n",
    "#lmr=LinearRegression()\n",
    "#sfs = SequentialFeatureSelector(lmr, n_features_to_select=50, n_jobs=16)\n",
    "#sfs.fit(X_train_cut, y_train)\n",
    "\n",
    "#get the relevant columns\n",
    "#features=sfs.get_support()\n",
    "#Features_selected =np.arange(M)[features]\n",
    "#print(\"The features selected are columns: \", Features_selected)\n",
    "\n",
    "#X_train_cut_sfs=sfs.transform(X_train_cut)\n",
    "#X_test_cut_sfs=sfs.transform(X_ivs_cut)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952ca76c",
   "metadata": {},
   "source": [
    "<h4>RFs for feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3399dee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureSelect(x_train, x_ivs, n_features, t):\n",
    "    rfr=RandomForestRegressor(random_state=0, n_jobs=6) #n_jobs=8\n",
    "    rfr.fit(x_train, y_train)\n",
    "    #for i, imp in enumerate(rfr.feature_importances_):\n",
    "    #    print(\"Feature\", i, \"Importance:\", imp )\n",
    "    \n",
    "    sel = SelectFromModel(estimator=rfr, threshold= t) #Change the threshold! See what happens!\n",
    "    sel.fit(x_train, y_train)\n",
    "    \n",
    "    #print(\"Importances: \", sel.estimator.feature_importances_)\n",
    "    \n",
    "    #print(\"Default threshold: \", sel.threshold_)\n",
    "    \n",
    "    features=sel.get_support()\n",
    "    Features_selected =np.arange(n_features)[features]\n",
    "    print(\"The features selected are columns: \", Features_selected,\".\\n Number of features:\", len(Features_selected))\n",
    "    \n",
    "    X_train_rffs=sel.transform(x_train)\n",
    "    X_test_rffs=sel.transform(x_ivs)\n",
    "    return X_train_rffs, X_test_rffs\n",
    "#naif_model_testingR(nX_train_cut, nX_test_cut, y_train, y_ivs) # y_ivs doesn't exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "80b03c65-0ab8-449e-b591-ea796349dee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The features selected are columns:  [   0    1    2    3    4    5    6    8    9   11   12   16   22   23\n",
      "   24   25   26   27   28   29   30   31   32   33   34   35   36   37\n",
      "   38   39   40   41   42  216  246  287  316  336  348  353  362  364\n",
      "  444  494  561  695  819  839  853  886  891  909  939  959  981  982\n",
      " 1013 1054 1087 1147 1161 1167 1176 1285 1440 1454 1499 1527 1598 1667\n",
      " 1687 1709 1841 1868 1921 1922 1968] .\n",
      " Number of features: 77\n"
     ]
    }
   ],
   "source": [
    "#takes around 5 min to execute\n",
    "X_train_rffs, X_test_rffs = featureSelect(X_train, X_ivs, M, .002)#.003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4356313-917f-4f30-be4c-a31afc006403",
   "metadata": {},
   "outputs": [],
   "source": [
    "#takes around 5 min to execute\n",
    "#Delete? probably not, since its possible to feature select in unscaled dataset, but it makes no sense to scale it after the feature selection is made.\n",
    "X_train_scaled_rffs, X_test_scaled_rffs = featureSelect(X_train_scaled, X_ivs_scaled, M, .002)#.003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6a5f93-2c17-4180-ad10-6a5e1004d4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cut_rffs, X_test_cut_rffs= featureSelect(X_train_cut, X_ivs_cut, M_cut, .005)#.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1580a5",
   "metadata": {},
   "source": [
    "<h4>Principal component analisys (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f9a929",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca(x_train, n_comps):\n",
    "    pca = PCA(n_components=n_comps)\n",
    "    pca.fit(x_train)\n",
    "    tve=0\n",
    "    for i, ve in enumerate(pca.explained_variance_ratio_):\n",
    "        tve+=ve\n",
    "    #    print(\"PC%d - Variance explained: %7.4f - Total Variance: %7.4f\" % (i, ve, tve) )\n",
    "    #print()\n",
    "    #print(\"Actual Eigenvalues:\", pca.singular_values_)\n",
    "    #for i,comp in enumerate(pca.components_):\n",
    "    #    print(\"PC\",i, \"-->\", comp)    \n",
    "    return pca\n",
    "\n",
    "def kpca(x_train, n_comps):\n",
    "    kpca = KernelPCA(n_components=n_comps, kernel='rbf')#, gamma=3)\n",
    "    kpca.fit(x_train)\n",
    "    X_train_kpca = kpca.transform(x_train)\n",
    "    return X_train_kpca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6254d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca1 = pca(X_train, 50) \n",
    "X_train_pca = pca1.transform(X_train)\n",
    "#X_test_pca=pca.transform(X_ivs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa0f9cf-c6d8-41cd-8a9a-b2e71f11fc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_kpca =kpca(X_train,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092add44-4336-4e85-bd1b-ad012cd63cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_scaled = pca(X_train_scaled, 50) \n",
    "X_train_scaled_pca = pca_scaled.transform(X_train_scaled)\n",
    "#X_test_scaled_pca=pca_scaled.transform(X_ivs_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20afd6f6-5429-45c6-946b-2406a4e5bede",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled_kpca =kpca(X_train_scaled,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ec5b00-3398-4861-a1b2-afe4355c2ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_cut = pca(X_train_cut, 50)\n",
    "X_train_cut_pca = pca_cut.transform(X_train_cut)\n",
    "#X_test_cut_pca=pca_cut.transform(X_ivs_cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fee1ee-28b4-4594-8249-2c974586ca06",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cut_kpca =kpca(X_train_cut,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6327c040-ab6c-4f7b-904f-5faa56139899",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_rffs = pca(X_train_rffs, 50)\n",
    "X_train_rffs_pca = pca_rffs.transform(X_train_rffs)\n",
    "#X_test_rffs_pca=pca_rffs.transform(X_test_rffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ffb0a2-051e-4669-9941-3ba3b78b1739",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rffs_kpca =kpca(X_train_rffs,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bdee35-ff0a-423d-930c-551ad7b0d17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pca_scaled_rffs\n",
    "pca_scaled_rffs = pca(X_train_scaled_rffs, 50)\n",
    "X_train_scaled_rffs_pca = pca_scaled_rffs.transform(X_train_scaled_rffs)\n",
    "#X_test_scaled_rffs_pca = pca_scaled_rffs.transform(X_test_scaled_rffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1514c36a-1da2-40a6-a0af-3043ea458c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled_rffs_kpca = kpca(X_train_scaled_rffs,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedba7e6-6974-4758-a3b2-409215c41e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_cut_rffs = pca(X_train_cut_rffs, 5)\n",
    "X_train_cut_rffs_pca=pca_cut_rffs.transform(X_train_cut_rffs)\n",
    "#X_test_cut_rffs_pca=pca_cut.transform(X_test_cut_rffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b68e82c-1499-40a6-948c-df2d93f22835",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cut_rffs_kpca = kpca(X_train_cut_rffs,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b50ca8",
   "metadata": {},
   "source": [
    "<h3>Cross-validation. Evaluation of the (models) and data configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba74a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printAvalStat(truth, preds):\n",
    "    print(\"The RVE is: \", explained_variance_score(truth, preds))\n",
    "    print(\"The rmse is: \", mean_squared_error(truth, preds, squared=False))\n",
    "    corr, pval=pearsonr(truth, preds)\n",
    "    print(\"The Correlation Score is: %6.4f (p-value=%e)\"%(corr,pval))\n",
    "\n",
    "    print(\"The Maximum Error is: \", max_error(truth, preds))\n",
    "    print(\"The Mean Absolute Error is:\", mean_absolute_error(truth, preds),\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ec27ca",
   "metadata": {},
   "source": [
    "<h4>N-Fold Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511ffe3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nfold_valid(X_train_Valids):\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=23)\n",
    "    kf.get_n_splits(X_train_Valids)\n",
    "    TRUTH_nfold=None\n",
    "    PREDS_nfold=None\n",
    "    for train_index, test_index in kf.split(X_train_Valids):\n",
    "        X_train_nfold, X_ivs_nfold = X_train_Valids[train_index], X_train_Valids[test_index]\n",
    "        y_train_nfold, y_ivs_nfold = y_train[train_index], y_train[test_index]\n",
    "\n",
    "        #mdl = DecisionTreeRegressor()#max_depth = 5)\n",
    "        mdl = RandomForestRegressor(n_estimators=10, random_state=0, min_samples_leaf=3, max_depth = 8, n_jobs=6)\n",
    "        mdl.fit(X_train_nfold, y_train_nfold)\n",
    "        preds = mdl.predict(X_ivs_nfold)\n",
    "        if TRUTH_nfold is None:\n",
    "            PREDS_nfold=preds\n",
    "            TRUTH_nfold=y_ivs_nfold\n",
    "        else:\n",
    "            PREDS_nfold=np.hstack((PREDS_nfold, preds))\n",
    "            TRUTH_nfold=np.hstack((TRUTH_nfold, y_ivs_nfold))\n",
    "        \n",
    "    printAvalStat(TRUTH_nfold, PREDS_nfold)\n",
    "\n",
    "#print(\"N-fold cross validation of nXf_train, after sequencial reduction feature selection\")\n",
    "#nfold_valid(nXf_train)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa3d324-7c5e-46a6-ad04-2de4dfe661dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first unchanged data evaluations\n",
    "print(\"N-fold cross validation of X_train\")\n",
    "nfold_valid(X_train)\n",
    "print(\"N-fold cross validation of X_train_scaled\")\n",
    "nfold_valid(X_train_scaled)\n",
    "\n",
    "#manually cut features data evaluations\n",
    "print(\"N-fold cross validation of X_train_cut(already scaled!)\")\n",
    "nfold_valid(X_train_cut)\n",
    "\n",
    "#feature selected data evaluations\n",
    "print(\"N-fold cross validation of X_train_rffs\")\n",
    "nfold_valid(X_train_rffs)\n",
    "print(\"N-fold cross validation of X_train_scaled_rffs\")\n",
    "nfold_valid(X_train_scaled_rffs)\n",
    "\n",
    "#cut x feature selected data evaluation\n",
    "print(\"N-fold cross validation of X_train_cut_rffs(already scaled!)\")\n",
    "nfold_valid(X_train_cut_rffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccab7bff-953a-4ecb-ac4c-f34d1a6c8e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pca evaluations\n",
    "print(\"N-fold cross validation of X_train_pca\")\n",
    "nfold_valid(X_train_pca)\n",
    "print(\"N-fold cross validation of X_train_scaled_pca\")\n",
    "nfold_valid(X_train_scaled_pca)\n",
    "\n",
    "print(\"N-fold cross validation of X_train_cut_pca(already scaled!)\")\n",
    "nfold_valid(X_train_cut_pca)\n",
    "\n",
    "print(\"N-fold cross validation of X_train_rffs_pca\")\n",
    "nfold_valid(X_train_rffs_pca)\n",
    "print(\"N-fold cross validation of X_train_scaled_rffs_pca\")\n",
    "nfold_valid(X_train_scaled_rffs_pca)\n",
    "\n",
    "print(\"N-fold cross validation of X_train_cut_rffs_pca(already scaled!)\")\n",
    "nfold_valid(X_train_cut_rffs_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e13f58-251a-4684-81d2-77a478f34ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kpca evaluations\n",
    "print(\"N-fold cross validation of X_train_kpca\")\n",
    "nfold_valid(X_train_kpca)\n",
    "print(\"N-fold cross validation of X_train_scaled_kpca\")\n",
    "nfold_valid(X_train_scaled_kpca)\n",
    "\n",
    "print(\"N-fold cross validation of X_train_cut_kpca(already scaled!)\")\n",
    "nfold_valid(X_train_cut_kpca)\n",
    "\n",
    "print(\"N-fold cross validation of X_train_rffs_kpca\")\n",
    "nfold_valid(X_train_rffs_kpca)\n",
    "print(\"N-fold cross validation of X_train_scaled_rffs_kpca\")\n",
    "nfold_valid(X_train_scaled_rffs_kpca)\n",
    "\n",
    "print(\"N-fold cross validation of X_train_cut_rffs_kpca(already scaled!)\")\n",
    "nfold_valid(X_train_cut_rffs_kpca)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13965578-d709-4b43-9de7-35e3b72788b9",
   "metadata": {},
   "source": [
    "<h5>\n",
    "Com estes resultados concluímos que o data tretment que efetuámos não afeta consideravelmente a qualidade dos modelos resultantes.\n",
    "<br>\n",
    "De salientar que os modelos resultantes dos dados manualmente cortados, que resultou numa redução de features de 2000+ para 377, tem resultados muito semelhantes aos modelos que usam todas as 2000+ features.\n",
    "<br>\n",
    "Por isso achamos que só o uso de mais e diferentes modelos para além de random forest é que poderemos melhorar o resultado das previsões.\n",
    "</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bbaa10-1cdf-4a5a-93a0-71c74e7937e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nfold_valid_mt(X_train_Valids):\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=23)\n",
    "    kf.get_n_splits(X_train_Valids)\n",
    "    TRUTH_nfold=None\n",
    "    PREDS_nfold=None\n",
    "    for train_index, test_index in kf.split(X_train_Valids):\n",
    "        X_train_nfold, X_ivs_nfold = X_train_Valids[train_index], X_train_Valids[test_index]\n",
    "        y_train_nfold, y_ivs_nfold = y_train[train_index], y_train[test_index]\n",
    "    \n",
    "    gammas = [1e-1, 1e-2, 1e-3, 1e-4, 1e-5, 1e-6, 1e-7]\n",
    "    Cs = [1, 10, 100, 1e3, 1e4, 1e5]\n",
    "    param_grid = {\"gamma\": gammas, \"C\": Cs}\n",
    "    \n",
    "    #define the model and do the grid search\n",
    "    svr = SVR()\n",
    "    gs = GridSearchCV(estimator=svr, param_grid=param_grid, scoring=\"explained_variance\")\n",
    "    mdl = gs.fit(X_train_Valids, y_train)\n",
    "    preds = mdl.predict(X_ivs_nfold)\n",
    "    if TRUTH_nfold is None:\n",
    "        PREDS_nfold=preds\n",
    "        TRUTH_nfold=y_ivs_nfold\n",
    "    else:\n",
    "        PREDS_nfold=np.hstack((PREDS_nfold, preds))\n",
    "        TRUTH_nfold=np.hstack((TRUTH_nfold, y_ivs_nfold))\n",
    "        \n",
    "    printAvalStat(TRUTH_nfold, PREDS_nfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d2941c-d727-403a-a9ae-bd6990684282",
   "metadata": {},
   "outputs": [],
   "source": [
    "nfold_valid_mt(X_train_cut_kpca)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8179ff-fe50-41e9-8b09-9b07389443d5",
   "metadata": {},
   "source": [
    "<h3>New Models</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3964d6b",
   "metadata": {},
   "source": [
    "<h4>Leave-one-out cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5be3205",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LeaveOneOut_val(X_train_Valids):\n",
    "    loo = LeaveOneOut()\n",
    "    loo.get_n_splits(X_train_Valids)\n",
    "\n",
    "    TRUTH_loo=[]\n",
    "    PREDS_loo=[]\n",
    "\n",
    "    for train_index, test_index in loo.split(X_train_Valids):\n",
    "        X_train_loo, X_test_loo = X_train_Valids[train_index], X_train_Valids[test_index]\n",
    "        y_train_loo, y_test_loo = y_train[train_index], y_train[test_index]\n",
    "\n",
    "        mdl = DecisionTreeRegressor()#max_depth = 5)\n",
    "        mdl.fit(X_train_loo, y_train_loo)\n",
    "        pred = mdl.predict(X_test_loo)\n",
    "        PREDS_loo.append(pred)\n",
    "        TRUTH_loo.append(y_test_loo)\n",
    "\n",
    "    printAvalStat(TRUTH_nfold, PREDS_nfold)\n",
    "        \n",
    "print(\"Leave-one-out cross validation of X_train\")\n",
    "LeaveOneOut_val(X_train)\n",
    "print(\"Leave-one-out cross validation of nX_train, after PCA\")\n",
    "LeaveOneOut_val(nX_train)\n",
    "#print(\"Leave-one-out cross validation of nXf_train, after sequencial reduction feature selection\")\n",
    "#LeaveOneOut_val(nXf_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fb6a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gammas = [1e-1, 1e-2, 1e-3, 1e-4, 1e-5, 1e-6, 1e-7]\n",
    "#Cs = [1, 10, 100, 1e3, 1e4, 1e5]\n",
    "#param_grid = {\"gamma\": gammas, \"C\": Cs}\n",
    "\n",
    "#svr = SVR()\n",
    "#gs = GridSearchCV(estimator=svr, param_grid=param_grid, scoring=\"explained_variance\")\n",
    "#gs=gs.fit(X_train, y_train)\n",
    "\n",
    "#res = pd.DataFrame(gs.cv_results_)\n",
    "#res = res.sort_values(by=[\"rank_test_score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9671a2",
   "metadata": {},
   "source": [
    "<h4> Random Forest Regressor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49249097",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DisplayRegResults(y_test, preds):\n",
    "    print(\"RVE: %7.4f\"  % explained_variance_score(y_test, preds))\n",
    "    print(\"rmse: %7.4f\" % mean_squared_error(y_test, preds, squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbd8e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(n_estimators=10, random_state=0, min_samples_leaf=3)\n",
    "rf.fit(X_train_scaled, y_train)\n",
    "preds=rf.predict(X_ivs_scaled)\n",
    "\n",
    "DisplayRegResults(y_test, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b60e0db",
   "metadata": {},
   "source": [
    "<h3>Objective:<br> Produce the best regression model for y_ivs (Dependent Variable)</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83db0a9a",
   "metadata": {},
   "source": [
    "Decision tree Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0f4be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dmdl = DecisionTreeRegressor(max_depth=5)\n",
    "dmdl.fit(X_train, y_train)\n",
    "\n",
    "dtr_preds=dmdl.predict(X_test)\n",
    "\n",
    "#explained_variance_score(y_test, dtr_preds)\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "r=tree.plot_tree(dmdl, filled=True)#, feature_names= df.columns)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8029b3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmses_i = []\n",
    "rmses_j = []\n",
    "\n",
    "#def statGraph()\n",
    "for i in range(1, 11):\n",
    "    dmdl_i = DecisionTreeRegressor(max_depth=i)\n",
    "    dmdl_i.fit(X_train, y_train)\n",
    "    \n",
    "    preds_i=dmdl_i.predict(X_test)\n",
    "    #= explained_variance_score(y_test, preds)\n",
    "    rmses_i.append(mean_squared_error(y_test, preds_i, squared=False))\n",
    "    \n",
    "for i in range(1, 41):\n",
    "    dmdl_j = DecisionTreeRegressor(max_depth=5, min_samples_leaf= i)\n",
    "    dmdl_j.fit(X_train, y_train)\n",
    "    \n",
    "    preds_j=dmdl_j.predict(X_test)\n",
    "    #= explained_variance_score(y_test, preds)\n",
    "    rmses_j.append(mean_squared_error(y_test, preds_j, squared=False))\n",
    "\n",
    "plt.figure(figsize=(3,3))\n",
    "plt.plot(range(1, 11), rmses_i)\n",
    "plt.xlabel(\"max_depth\")\n",
    "plt.ylabel(\"rmse\")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(3,3))\n",
    "plt.plot(range(1, 41), rmses_j)\n",
    "plt.xlabel(\"min_samples_leaf\")\n",
    "plt.ylabel(\"rmse\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e60aec",
   "metadata": {},
   "source": [
    "Linear Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a55a9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LinearRegression()\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "lr_preds=reg.predict(X_test)\n",
    "\n",
    "#explained_variance_score(y_test, lr_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33048246",
   "metadata": {},
   "source": [
    "Alternative linear regression model using statusmodel implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7153c00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr = add_constant(X_train)\n",
    "reg2=OLS(y_train,X_tr, hasconst=12).fit()\n",
    "reg2.summary()\n",
    "\n",
    "#alr_preds= reg2.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ab94b3",
   "metadata": {},
   "source": [
    "Regularized linear models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71799e7",
   "metadata": {},
   "source": [
    "Ridge Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36958bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = Ridge(alpha=10, max_iter=9999999).fit(X_train, y_train)\n",
    "\n",
    "print(\"The bias is: \",  ridge.intercept_)\n",
    "print(\"The other parameters are: \")\n",
    "#for i, beta in enumerate(ridge.coef_):\n",
    "#    print(\"\\t B%02d -> %9.3f\"% (i+1, beta))\n",
    "\n",
    "ridge_preds=ridge.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b37cde7",
   "metadata": {},
   "source": [
    "Lasso Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157655b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso(alpha=10, max_iter=9999999).fit(X_train, y_train)\n",
    "\n",
    "print(\"The bias is: \",  lasso.intercept_)\n",
    "print(\"The other parameters are: \")\n",
    "#for i, beta in enumerate(ridge.coef_):\n",
    "#    print(\"\\t B%02d -> %9.3f\"% (i+1, beta))\n",
    "\n",
    "lasso_preds= lasso.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62839ec5",
   "metadata": {},
   "source": [
    "Gráficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495c40a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawGraf(preds, title):\n",
    "    plt.figure(figsize=(3,3))\n",
    "    plt.scatter(preds, y_test)\n",
    "    plt.plot((0, 150), (0,150), c=\"r\")\n",
    "    plt.grid()\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Truth\")\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "#####  Gráfico linear regression #########\n",
    "drawGraf(lr_preds, \"Linear Regression\")\n",
    "\n",
    "#####  Gráfico decision tree regression #########\n",
    "drawGraf(dtr_preds, \"Decision Tree Regression\")\n",
    "\n",
    "#####  Gráfico ridge regression #########\n",
    "drawGraf(ridge_preds, \"Ridge Regression\")\n",
    "\n",
    "#####  Gráfico lasso regression #########\n",
    "drawGraf(lasso_preds, \"Lasso Regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4d49fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printAvalStat(truth, preds):\n",
    "    print(\"The RVE is: \", explained_variance_score(truth, preds))\n",
    "    print(\"The rmse is: \", mean_squared_error(truth, preds, squared=False))\n",
    "    corr, pval=pearsonr(truth, preds)\n",
    "    print(\"The Correlation Score is: %6.4f (p-value=%e)\"%(corr,pval))\n",
    "\n",
    "    print(\"The Maximum Error is: \", max_error(truth, preds))\n",
    "    print(\"The Mean Absolute Error is:\", mean_absolute_error(truth, preds),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb11eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############   Métricas de avaliação de decision tree regression\n",
    "print(\"Métricas de avaliação de decision tree regression:\")\n",
    "printAvalStat(y_test, dtr_preds)\n",
    "\n",
    "###############   Métricas de avaliação de linear regression\n",
    "print(\"Métricas de avaliação de linear regression:\")\n",
    "printAvalStat(y_test, lr_preds)\n",
    "\n",
    "###############   Métricas de avaliação de ridge regression\n",
    "print(\"Métricas de avaliação de ridge regression:\")\n",
    "printAvalStat(y_test, ridge_preds)\n",
    "\n",
    "###############   Métricas de avaliação de lasso regression\n",
    "print(\"Métricas de avaliação de lasso regression:\")\n",
    "printAvalStat(y_test, lasso_preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
